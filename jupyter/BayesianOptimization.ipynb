{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BayesianOptimization.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"WJq9Qn3da4Vl"},"source":["from xgboost import XGBClassifier\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelBinarizer, label_binarize\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","from lightgbm import LGBMClassifier\n","import pandas as pd\n","import numpy as np\n","from tqdm.notebook import tqdm\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from imblearn.over_sampling import SMOTE\n","from bayes_opt import BayesianOptimization\n","import warnings\n","import time\n","import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wqToahmidUbL","outputId":"53489fc5-b0d2-4d38-b272-d6f1c7235326","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install bayesian-optimization"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting bayesian-optimization\n","  Downloading https://files.pythonhosted.org/packages/bb/7a/fd8059a3881d3ab37ac8f72f56b73937a14e8bb14a9733e68cc8b17dbe3c/bayesian-optimization-1.2.0.tar.gz\n","Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.18.5)\n","Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.4.1)\n","Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.17.0)\n","Building wheels for collected packages: bayesian-optimization\n","  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-cp36-none-any.whl size=11685 sha256=9999982357774af00304707ff63c916c75f3baed4ec3e43ca8385bd7f5459ead\n","  Stored in directory: /root/.cache/pip/wheels/5a/56/ae/e0e3c1fc1954dc3ec712e2df547235ed072b448094d8f94aec\n","Successfully built bayesian-optimization\n","Installing collected packages: bayesian-optimization\n","Successfully installed bayesian-optimization-1.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qu39b_Lga575"},"source":["def XGB_CV(max_depth,\n","           gamma,\n","           min_child_weight,\n","           max_delta_step,\n","           subsample,\n","           colsample_bytree,\n","           learning_rate,\n","         ):\n","    time2 = time.time()\n","    global AUCbest\n","    global ITERbest\n","    \n","    folds = 10\n","    cv_score = 0\n","    xgb = XGBClassifier(max_depth = int(max_depth),\n","                        gamma = gamma,\n","                        learning_rate = learning_rate,\n","                        subsample = max(min(subsample, 1), 0),\n","                        colsample_bytree = max(min(colsample_bytree, 1), 0),\n","                        min_child_weight = min_child_weight,\n","                        max_delta_step = int(max_delta_step),\n","                        n_estimators = 20000,\n","                        random_state=1234, \n","                        tree_method='gpu_hist' ,\n","                        silent=True)\n","    xgb.fit(X_train, y_train,\n","            early_stopping_rounds = 100,\n","            eval_set=[(X_test, y_test)], \n","            eval_metric=custom_eval, verbose=False)\n","    \n","    \n","    val_score = -xgb.evals_result()['validation_0']['roc_auc'][-1]\n","    print(' Stopped after %d iterations with val-auc = %f val-gini = %f' % ( len(xgb.evals_result()['validation_0']['roc_auc']), val_score, (val_score*2-1)) )\n","    if ( val_score > AUCbest ):\n","        AUCbest = val_score\n","        ITERbest = len(xgb.evals_result()['validation_0']['roc_auc'])\n","    time2 -=time.time()\n","\n","    return (val_score*2) - 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VS1lcktMcuHu"},"source":["def multiclass_roc_auc_score(y_test, y_pred_proba, average=None): #average='macro' when you wanna get mean\n","  lb = LabelBinarizer()\n","  lb.fit(y_test)\n","  y_test = lb.transform(y_test)\n","  #y_pred = lb.transform(y_pred)   #if y_pred_proba is not a probability\n","  roc_auc = roc_auc_score(y_test, y_pred_proba, average=average)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6_LkXD6Tz15W"},"source":["def custom_eval(pred, dtrain):\n","  labels = dtrain.get_label()\n","  lb = LabelBinarizer()\n","  lb.fit(labels)\n","  label = lb.transform(labels)\n","  return 'roc_auc' , -roc_auc_score(label, pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ahyRpPb9jIVi","outputId":"a68ae1e5-170a-492d-ff4d-d295022863fa","colab":{"base_uri":"https://localhost:8080/"}},"source":["%cd /content/drive/My Drive/samsung_card/preprocess  \n","\n","path = '../data/'\n","test_file = 'df_merged.csv'\n","df = pd.read_csv(path+test_file, index_col='cst_id_di')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/samsung_card/preprocess\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OK8MJt7pcxfP"},"source":["XGB_BO = BayesianOptimization(XGB_CV, {\n","                                    'max_depth': (2, 12),\n","                                    'gamma': (0.001, 10.0),\n","                                    'min_child_weight': (0, 20),\n","                                    'max_delta_step': (0, 10),\n","                                    'subsample': (0.4, 1.0),\n","                                    'colsample_bytree' :(0.4, 1.0),\n","                                    'learning_rate' : (0.01, 0.1)\n","                                    })"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wHy_9j7vvV-m"},"source":["X = df.iloc[:, 1:].values; y = df.iloc[:, 0].values\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1234)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IeIj3xGSc4GN","outputId":"6140a186-090c-4aaa-f53d-180487058b6c","colab":{"base_uri":"https://localhost:8080/"}},"source":["AUCbest = -1.\n","ITERbest = 0\n","with warnings.catch_warnings():\n","    warnings.filterwarnings('ignore')\n","    XGB_BO.maximize(init_points=2, n_iter=30, acq='ei', xi=0.0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["|   iter    |  target   | colsam... |   gamma   | learni... | max_de... | max_depth | min_ch... | subsample |\n","-------------------------------------------------------------------------------------------------------------\n"," Stopped after 408 iterations with val-auc = 0.886572 val-gini = 0.773144\n","| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7731  \u001b[0m | \u001b[0m 0.4939  \u001b[0m | \u001b[0m 4.715   \u001b[0m | \u001b[0m 0.06635 \u001b[0m | \u001b[0m 5.155   \u001b[0m | \u001b[0m 9.919   \u001b[0m | \u001b[0m 9.163   \u001b[0m | \u001b[0m 0.4351  \u001b[0m |\n"," Stopped after 330 iterations with val-auc = 0.886273 val-gini = 0.772546\n","| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7725  \u001b[0m | \u001b[0m 0.9182  \u001b[0m | \u001b[0m 1.465   \u001b[0m | \u001b[0m 0.09187 \u001b[0m | \u001b[0m 7.554   \u001b[0m | \u001b[0m 6.131   \u001b[0m | \u001b[0m 0.1714  \u001b[0m | \u001b[0m 0.7001  \u001b[0m |\n"," Stopped after 333 iterations with val-auc = 0.887737 val-gini = 0.775474\n","| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7755  \u001b[0m | \u001b[95m 0.4828  \u001b[0m | \u001b[95m 9.944   \u001b[0m | \u001b[95m 0.07899 \u001b[0m | \u001b[95m 6.583   \u001b[0m | \u001b[95m 10.98   \u001b[0m | \u001b[95m 15.32   \u001b[0m | \u001b[95m 0.6641  \u001b[0m |\n"," Stopped after 2180 iterations with val-auc = 0.888194 val-gini = 0.776388\n","| \u001b[95m 4       \u001b[0m | \u001b[95m 0.7764  \u001b[0m | \u001b[95m 0.4899  \u001b[0m | \u001b[95m 9.495   \u001b[0m | \u001b[95m 0.04922 \u001b[0m | \u001b[95m 9.682   \u001b[0m | \u001b[95m 2.199   \u001b[0m | \u001b[95m 19.92   \u001b[0m | \u001b[95m 0.8426  \u001b[0m |\n"," Stopped after 5503 iterations with val-auc = 0.888945 val-gini = 0.777890\n","| \u001b[95m 5       \u001b[0m | \u001b[95m 0.7779  \u001b[0m | \u001b[95m 0.4808  \u001b[0m | \u001b[95m 9.892   \u001b[0m | \u001b[95m 0.01833 \u001b[0m | \u001b[95m 2.855   \u001b[0m | \u001b[95m 2.674   \u001b[0m | \u001b[95m 19.97   \u001b[0m | \u001b[95m 0.4889  \u001b[0m |\n"," Stopped after 1446 iterations with val-auc = 0.888172 val-gini = 0.776344\n","| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7763  \u001b[0m | \u001b[0m 0.5854  \u001b[0m | \u001b[0m 8.854   \u001b[0m | \u001b[0m 0.08944 \u001b[0m | \u001b[0m 0.1437  \u001b[0m | \u001b[0m 2.484   \u001b[0m | \u001b[0m 19.81   \u001b[0m | \u001b[0m 0.5319  \u001b[0m |\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OKEEZesedpgz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y0uhx_xh9iSb"},"source":["def XGB_CV(max_depth,\n","           gamma,\n","           min_child_weight,\n","           max_delta_step,\n","           subsample,\n","           colsample_bytree,\n","           learning_rate,\n","         ):\n","\n","    global AUCbest\n","    global ITERbest\n","\n","    folds = 10\n","    cv_score = 0\n","\n","    lg = lgb.LGBMClassifier(class_weight=None,\n","                        colsample_bytree=0.9234, learning_rate=0.01, max_depth=20, \n","                        min_child_weight=0.1, min_split_gain=0.0, n_estimators=150, \n","                        n_jobs=-1, num_leaves=13, random_state=42, silent=True)\n","    \n","\n","    xgb = XGBClassifier(max_depth = int(max_depth),\n","                        gamma = gamma,\n","                        learning_rate = learning_rate,\n","                        subsample = max(min(subsample, 1), 0),\n","                        colsample_bytree = max(min(colsample_bytree, 1), 0),\n","                        min_child_weight = min_child_weight,\n","                        max_delta_step = int(max_delta_step),\n","                        n_estimators = 20000,\n","                        random_state=1234, \n","                        tree_method='gpu_hist' ,\n","                        silent=True)\n","    xgb.fit(X_train, y_train,\n","            verbose=False,  \n","            early_stopping_rounds = 100,\n","            eval_set=[(X_test, y_test)],\n","            eval_metric=custom_eval, )\n","\n","    \n","    val_score = xgb.evals_result()['validation_0']['roc_auc'][-1]\n","    print(' Stopped after %d iterations with val-auc = %f val-gini = %f' % ( len(xgb.evals_result()['validation_0']['roc_auc']), val_score, (val_score*2-1)) )\n","    if ( val_score > AUCbest ):\n","        AUCbest = val_score\n","        ITERbest = len(xgb.evals_result()['validation_0']['roc_auc'])\n","\n","    return (val_score*2) - 1"],"execution_count":null,"outputs":[]}]}